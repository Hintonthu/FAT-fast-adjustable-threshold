{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppress unnecessary warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import scripts.mnasnet.combined_tools as ct\n",
    "from scripts import helpers as hp\n",
    "from scripts.thresholds import eval_thresholds\n",
    "from scripts.data.data_generator import DataGenerator\n",
    "from scripts.trainer.trainer import Trainer\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # limit usage down to one 0-th GPU (use -1 to use CPU) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare model data and environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Specify the path to the __*.pickle__ file `weights_path` containing weights of the MNasNet model you want to quantize.\n",
    "2. Specify the output folder `output_dir_name`, where the results produced by this notebook will be stored\n",
    " \n",
    "Size of the input images will be retrieved automatically (we pick the last number from the model name). If the size can not be retrieved, you can specify the parameter `input_size` explicitly or the input size will be 224px by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_path = \"../storage/mnasnet_original/mnasnet_1.0_128_weights.pickle\"\n",
    "output_dir_name = \"../storage/mnasnet_processed/\"\n",
    "\n",
    "INPUT_SHAPE, ckpt, best_ckpt, thresholds_path, fakequant_pb = ct.prepare_mnasnet_environment(weights_path, \n",
    "                                                                                             output_dir_name, \n",
    "                                                                                             input_size=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`train_labels` and `val_labels` are paths to the files containing lists in the following format:\n",
    "```\n",
    "rel/path/to_img_1.JPEG label_1\n",
    "rel/path/to_img_2.JPEG label_2\n",
    "...\n",
    "```\n",
    "Path to each image specified in these lists must be relative to the folders `train_images` and `val_images` correspondingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = \"/path/to/train/images/folder/\"\n",
    "train_labels = \"/path/to/train/data/list.txt\"\n",
    "val_images = \"/path/to/validation/images/folder/\"\n",
    "val_labels = \"/path/to/validation/data/list.txt\"\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------\n",
    "hp.check_paths_exist(train_images, train_labels, val_images, val_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Validation and Training data generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = DataGenerator(train_images, train_labels, hp.googlenet_preprocess, imsize=INPUT_SHAPE[1])\n",
    "valid_gen = DataGenerator(val_images, val_labels, hp.googlenet_preprocess, imsize=INPUT_SHAPE[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calibration data generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The calibrator for the MNasNet uses lesser number of batched images and does not use the information about labels.\n",
    "We wrap the train data generator into the `cal_data_generator` function to preprocess the `train_gen` data before feeding it for calibration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_calibration_batches = 1\n",
    "imgs_per_calibration_batch = 100\n",
    "\n",
    "def cal_data_generator():\n",
    "    for imgs, _ in train_gen.generate_batches(imgs_per_calibration_batch, number_of_calibration_batches):\n",
    "        yield imgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating initial quantization thresholds from the original model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "WEIGHTS = hp.load_pickle(weights_path)\n",
    "\n",
    "float_model = ct.create_float_model(ct.create_input_node(INPUT_SHAPE), WEIGHTS)\n",
    "\n",
    "with tf.Session(graph=float_model.graph) as sess:\n",
    "    THRESHOLDS = eval_thresholds(sess, float_model.input_node, float_model.reference_nodes, cal_data_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_input_node = ct.create_input_node(INPUT_SHAPE)\n",
    "\n",
    "float_model, quant_model = ct.create_adjustable_model(train_input_node, WEIGHTS, THRESHOLDS)\n",
    "\n",
    "train_configuration_data = hp.load_json(\"settings_config/train.json\")\n",
    "\n",
    "# We override these parameters for better flexibility only, in order to automatically change \n",
    "# the output folders for different mnasnet models.\n",
    "# You can comment the following two lines to use ckpt paths specified by the configuration file\n",
    "train_configuration_data['save_dir'] = ckpt\n",
    "train_configuration_data['best_ckpt_dir'] = best_ckpt\n",
    "\n",
    "hp.clear_dir(ckpt)\n",
    "\n",
    "my_trainer = Trainer(train_input_node.graph, \n",
    "                     train_gen, \n",
    "                     valid_gen,\n",
    "                     train_input_node, \n",
    "                     float_model.output_node, \n",
    "                     quant_model.output_node, \n",
    "                     **train_configuration_data)  \n",
    "\n",
    "with tf.Session(graph=train_input_node.graph) as sess:\n",
    "    with sess.graph.as_default():\n",
    "        \n",
    "        sess.run(quant_model.initializer)\n",
    "        \n",
    "        # check accuracy of the original model\n",
    "        print(\"Check accuracy of the original model ...\")\n",
    "        original_top1, _ = my_trainer.validate(sess, False)\n",
    "        print(\"Original top 1:\", original_top1)\n",
    "        \n",
    "        # check accuracy of the non-trained quantized model\n",
    "        print(\"Check accuracy  of the non-trained quantized model ...\")\n",
    "        initial_top1, _ = my_trainer.validate(sess)\n",
    "        print(\"Initial top 1:\", initial_top1)\n",
    "        \n",
    "        # train thresholds\n",
    "        print(\"Training thresholds of the quantized model ...\")\n",
    "        my_trainer.train(sess)\n",
    "        \n",
    "        # save trained thresholds\n",
    "        adjusted_thresholds = sess.run(quant_model.adjusted_thresholds)\n",
    "        hp.save_pickle(adjusted_thresholds, thresholds_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model with fakequant nodes based on adjusted quantization thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fakequant_model = ct.create_fakequant_model(ct.create_input_node(INPUT_SHAPE), WEIGHTS, adjusted_thresholds)\n",
    "hp.save_pb(fakequant_model.graph, fakequant_pb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
